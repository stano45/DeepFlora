{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepFlora.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stano45/DeepFlora/blob/main/DeepFlora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8udbI62Ljmeo"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import IPython\n",
        "import functools\n",
        "from PIL import Image # image processing\n",
        "from tqdm import tqdm # ranges are displayed \n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import random\n",
        "import math\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH7h3CGFjlBH"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices()[1].physical_device_desc)\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw6leZoTrxau"
      },
      "source": [
        "def mkdir (name):\n",
        "    if not os.path.exists(name):\n",
        "        os.mkdir(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5tjgYuKofiP"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"kaggle.json\"):\n",
        "  files.upload() #upload kaggle.json\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "DATASET_NAMES = ['mushrooms-classification-common-genuss-images']\n",
        "\n",
        "!kaggle datasets download -d maysee/mushrooms-classification-common-genuss-images --force\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iod469kv1KbY"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "mkdir('datasets')\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "for dataset in DATASET_NAMES:\n",
        "  with zipfile.ZipFile(dataset + \".zip\",\"r\") as z:\n",
        "    z.extractall(\"datasets\")\n",
        "  os.remove(dataset + \".zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHv4XqmxuQmF"
      },
      "source": [
        "\"\"\"\n",
        "process all datasets and clear space\n",
        "\"\"\"\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#path to datasets\n",
        "DATASET_PATH = 'datasets' \n",
        "\n",
        "#path to processed images\n",
        "PROCESSED_PATH = \"processed_data\"\n",
        "mkdir(PROCESSED_PATH)\n",
        "\n",
        "dataset_info = dict()\n",
        "\n",
        "#size of resized images\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "#number of removed images due to insufficient size\n",
        "#(avoid having to add padding, that is bad for training)\n",
        "removed_total = 0\n",
        "\n",
        "#iterate over all datasets\n",
        "datasets = os.listdir(DATASET_PATH)\n",
        "for dataset in datasets:\n",
        "\n",
        "    if (dataset == 'mushrooms'):\n",
        "      continue\n",
        "\n",
        "    #iterate over all categories in dataset\n",
        "    categories_path = os.path.join(DATASET_PATH, dataset)\n",
        "    categories = os.listdir(categories_path)\n",
        "\n",
        "    processed_dataset = os.path.join(PROCESSED_PATH, dataset.lower())\n",
        "    mkdir(processed_dataset)\n",
        "    \n",
        "    dataset_info[dataset.lower()] = dict()\n",
        "    for category in categories:\n",
        "        \n",
        "        dataset_info[dataset.lower()][category.lower()] = 0\n",
        "\n",
        "        #iterate over all images in category\n",
        "        category_path = os.path.join(categories_path, category)\n",
        "\n",
        "        processed_category = os.path.join(processed_dataset, category.lower())\n",
        "        mkdir(processed_category)\n",
        "        \n",
        "        images = os.listdir(category_path)\n",
        "        t_images = tqdm(images)\n",
        "        t_images.set_description(\"Parsing category {} from dataset {}\".format(category, dataset))\n",
        "\n",
        "        for image in t_images:\n",
        "            \n",
        "            # if the image format is not jpg then skip it\n",
        "            if not any([image.endswith(x) for x in [\".jpg\", \".jpeg\"]]):\n",
        "              continue\n",
        "\n",
        "            #if image in os.listdir(processed_category):\n",
        "            #  continue\n",
        "\n",
        "            # image is loaded\n",
        "            img = Image.open(os.path.join(category_path, image))\n",
        "\n",
        "            if img.size < IMG_SIZE:\n",
        "              removed_total += 1\n",
        "              continue\n",
        "\n",
        "            # images resized to the given size, save image, delete old version\n",
        "            img = img.resize(IMG_SIZE)\n",
        "            img.save(os.path.join(processed_category, image))\n",
        "            \n",
        "            dataset_info[dataset.lower()][category.lower()] += 1\n",
        "        \n",
        "\n",
        "print(dataset_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewbNrGXN2xBR"
      },
      "source": [
        "\"\"\"\n",
        "!!!Deletes all unprocessed datasets!!!\n",
        "Execute this block if not enough space on disk\n",
        "\"\"\"\n",
        "!rm -R datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeUjMXo0ZAml"
      },
      "source": [
        "def get_count_in_dataset(dataset : str):\n",
        "  return sum(list(dataset_info[dataset].values()))\n",
        "\n",
        "get_count_in_dataset(\"mushrooms\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ1z1zkQaYiw"
      },
      "source": [
        "TRAIN_PERCENT = 0.8 #percentage of training data from all data, range (0,1)\n",
        "VAL_PERCENT = 0.2 #percentage of validation data from training data, range (0,1)\n",
        "\n",
        "for dataset in dataset_info:\n",
        "\n",
        "  #change directories to the right dataset, create train, test and val folders\n",
        "  dataset_path = os.path.join('/content', PROCESSED_PATH, dataset)\n",
        "  os.chdir(dataset_path)\n",
        "  mkdir('train')\n",
        "  train_path = os.path.join(dataset_path, 'train')\n",
        "  mkdir('val')\n",
        "  val_path = os.path.join(dataset_path, 'val')\n",
        "  mkdir('test')\n",
        "  test_path = os.path.join(dataset_path, 'test')\n",
        "\n",
        "  for category in dataset_info[dataset]:\n",
        "\n",
        "    train_threshold = int((dataset_info[dataset][category] * TRAIN_PERCENT) - 1)\n",
        "    val_threshold = int(train_threshold * VAL_PERCENT)\n",
        "\n",
        "    #print(category, \" with {} images, t_thres={}, v_thres={}\".format(dataset_info[dataset][category], train_threshold, val_threshold))\n",
        "    v = 0\n",
        "    tr = 0\n",
        "    tes = 0\n",
        "    for i, image in enumerate(np.random.permutation(os.listdir(os.path.join(dataset_path, category)))):\n",
        "      source = os.path.join(dataset_path, category, image)\n",
        "      target = \"\"\n",
        "      if i < val_threshold:\n",
        "        target = val_path\n",
        "        #v += 1\n",
        "      elif i < train_threshold:\n",
        "        target = train_path\n",
        "        #tr += 1\n",
        "      else:\n",
        "        target = test_path\n",
        "        #tes += 1\n",
        "      \n",
        "      #new_dest = os.path.join(target, image)\n",
        "     # print(source, new_dest)\n",
        "      target = os.path.join(target, category + \"_{}\".format(i))\n",
        "      shutil.move(source, target)\n",
        "     # os.replace(source, new_dest)\n",
        "      \n",
        "    #print(v, tr, tes, v + tr + tes, dataset_info[dataset][category])\n",
        "    os.rmdir(category)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo79dAPx0CGG"
      },
      "source": [
        "last_indices = np.zeros(len(categories), dtype=int)\n",
        "\n",
        "\n",
        "\n",
        "def get_batch(dataset, num_samples, use='train'):\n",
        "    images_left = num_per_dataset[dataset]\n",
        "    if images_left < num_samples:\n",
        "        raise Exception(\"Insufficient amount of unseen samples in dataset!\")\n",
        "    \n",
        "    categories = categories_per_dataset[dataset]\n",
        "    samples_per_category = math.ceil(num_samples / len(categories))\n",
        "\n",
        "    if samples_per_category == 0:\n",
        "        print(\"Warning: number of samples less than number of categories, last n categories won't be picked from!\")\n",
        "        samples_per_category = 1\n",
        "    \n",
        "    #x = batch, y = labels\n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    #iterate until all samples evenly distributed or no more left in dataset\n",
        "    while num_samples > 0 and images_left > 0:\n",
        "        \n",
        "        #iterate starting from first category\n",
        "        for i, category in enumerate(categories):\n",
        "\n",
        "            #get path of category and list all images\n",
        "            path = os.path.join(PROCESSED_PATH, dataset, category)\n",
        "            images = os.listdir(path)\n",
        "\n",
        "            #pick from each category samples_per_category\n",
        "            #or the remaining num_samples if less than samples_per_category\n",
        "            for j in range(min(samples_per_category, num_samples)):\n",
        "\n",
        "                #check if category not empty\n",
        "                if last_indices[i] < len(images):\n",
        "\n",
        "                    #get new image\n",
        "                    image_path = os.path.join(path,images[last_indices[i]])\n",
        "                    image = Image.open(image_path)\n",
        "\n",
        "                    #save image and label\n",
        "                    x.append(tf.Variable(tf.keras.preprocessing.image.img_to_array(image)))\n",
        "                    y.append(i)\n",
        "\n",
        "                    #move indeces\n",
        "                    last_indices[i] += 1\n",
        "                    num_samples -= 1\n",
        "                    images_left -= 1\n",
        "\n",
        "    return x, y\n",
        "\n",
        "for i in range(5):\n",
        "  x,y = get_batch('mushrooms', 6500)\n",
        "  print(\"y = \", y)\n",
        "  print(last_indices)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c82Aum-T5PZ"
      },
      "source": [
        "def accuracy(y1: tf.Variable, y2: tf.Variable):\n",
        "    a, b = y1.numpy(), y2.numpy()\n",
        "    if a.shape != b.shape:\n",
        "        return 0.0\n",
        "    sum_of_tru = sum([a==b for a,b in zip(a, b)])\n",
        "    avg = su/len(a)\n",
        "    return avg\n",
        "\n",
        "def train_batch(model, x, y, loss_fn, optimizer_fn, metric_fn=None):\n",
        "    if optimizer_fn is None:\n",
        "        pred = model(x)\n",
        "    else:\n",
        "        with tf.GradientTape() as tape:\n",
        "            pred = model(x)\n",
        "    loss = loss_fn(y, pred)\n",
        "    metric = None\n",
        "    if metric_fn is not None:\n",
        "        metric = metric_fn(y, pred)\n",
        "    if optimizer_fn is not None:\n",
        "        grad = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer_fn.apply_gradients(zip(model.trainable_variables, grad))\n",
        "    return pred, loss, metric\n",
        "\n",
        "def train(model, x, y, epochs, batch_size, loss_fn, optimizer_fn, metric_fn=None):\n",
        "\n",
        "    # random permutation von 0 bis len(y)-1\n",
        "    random_indices = np.random.permutation(len(y))\n",
        "\n",
        "    # offset ist hier die anzahl \n",
        "    offset = len(y)//batch_size\n",
        "\n",
        "    # 0 arrays for losses and metrics\n",
        "    losses = [0 for x in range(epochs)]\n",
        "    metrics = [0 for x in range(epochs)]\n",
        "    test_losses = [0 for x in range(epochs)]\n",
        "    test_metrics = [0 for x in range(epochs)]\n",
        "\n",
        "    # train test split\n",
        "    # train_dataset, test_dataset = split(dataset, test_rate)\n",
        "\n",
        "    for i, b in nqdm(epochs, offset):\n",
        "        # get x, y\n",
        "        tensors, labels = get_batch(train_dataset, batch_size)\n",
        "\n",
        "        # get test data\n",
        "        test_tensors, test_labels = get_batch(test_dataset, batch_size)\n",
        "\n",
        "        # get y_pred\n",
        "        preds, loss, _ = train_batch(model, tensors, labels, loss_fn, optimizer_fn, metric_fn)\n",
        "\n",
        "        # get y_test_pred\n",
        "        test_preds, test_loss, test_metric = train_batch(model, tensors, labels, loss_fn, optimizer_fn=None, metric_fn)\n",
        "\n",
        "        # add losses together\n",
        "        losses[i] += loss\n",
        "        test_losses[i] += test_loss\n",
        "\n",
        "        # calculate metric (if metric_fn is defined)\n",
        "        metric = None\n",
        "        test_metric = None\n",
        "        if metric_fn is not None:\n",
        "            metric = metric_fn(labels, preds)\n",
        "            test_metric = metric_fn(test_labels, test_preds)\n",
        "\n",
        "            # add metrics together \n",
        "            metrics[i] += metric\n",
        "            test_metrics[i] += test_metric\n",
        "    \n",
        "    # losses and metrics are plotted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS2ujiqb7IdS"
      },
      "source": [
        "# Training hyperparameters\n",
        "batch_size = 32\n",
        "num_epochs = 2  # keep small to run faster\n",
        "learning_rate = 5e-4\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate) # define our optimizer#parameters of CNN\n",
        "num_filters = 5\n",
        "\n",
        "#make model\n",
        "def cnn_classifier(num_outputs):\n",
        "    Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='same', activation='relu')\n",
        "    BatchNormalization = tf.keras.layers.BatchNormalization\n",
        "    Flatten = tf.keras.layers.Flatten\n",
        "    Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
        "    MaxPool2D = functools.partial(tf.keras.layers.MaxPool2D, pool_size=(2, 2), strides=None, padding=\"same\")\n",
        "    model = tf.keras.Sequential([    \n",
        "        # size = (120, 240)\n",
        "        \n",
        "        Conv2D(filters=32, kernel_size=5,  strides=2),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "        \n",
        "        Conv2D(filters=2*num_filters, kernel_size=5,  strides=2),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "\n",
        "        Conv2D(filters=4*num_filters, kernel_size=3,  strides=2),\n",
        "        BatchNormalization(),\n",
        "        MaxPool2D(),\n",
        "\n",
        "        Conv2D(filters=6*num_filters, kernel_size=3,  strides=2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(512),\n",
        "        Dense(num_outputs, activation=\"softmax\"),\n",
        "        \n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "cnn_model = cnn_classifier(5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}